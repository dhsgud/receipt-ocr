# Receipt Ledger Vision OCR Server - ë¼ì¦ˆë² ë¦¬íŒŒì´ 5 ì„¤ì¹˜ ê°€ì´ë“œ

**llama.cpp** ì„œë²„ë¥¼ ì‚¬ìš©í•œ Vision LLM ì˜ìˆ˜ì¦ OCR ì„œë²„

## ðŸ“‹ ì¤€ë¹„ë¬¼
- ë¼ì¦ˆë² ë¦¬íŒŒì´ 5 (**8GB RAM í•„ìˆ˜**)
- Raspberry Pi OS 64-bit (Bookworm)
- ì¸í„°ë„· ì—°ê²°
- ìµœì†Œ 10GB ì—¬ìœ  ì €ìž¥ê³µê°„ (ëª¨ë¸ í¬í•¨)
- Vision ëª¨ë¸ GGUF íŒŒì¼ (ì˜ˆ: LLaVA, SmolVLM, Qwen2-VL ë“±)

---

## ðŸš€ ì„¤ì¹˜ ë°©ë²•

### 1ë‹¨ê³„: íŒŒì¼ ë³µì‚¬

**SCPë¡œ ë³µì‚¬ (Windows PowerShell):**
```powershell
scp -r c:\Users\ikm11\Desktop\receipt-ocr\sync_server pi@192.168.x.x:~/receipt-ledger/
scp -r c:\Users\ikm11\Desktop\receipt-ocr\llama.cpp pi@192.168.x.x:~/receipt-ledger/
scp c:\Users\ikm11\Desktop\receipt-ocr\setup_llamacpp.sh pi@192.168.x.x:~/receipt-ledger/
```

### 2ë‹¨ê³„: llama.cpp ë¹Œë“œ (ë¼ì¦ˆë² ë¦¬íŒŒì´ì—ì„œ)

```bash
cd ~/receipt-ledger/llama.cpp
mkdir build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release
cmake --build . --config Release -j4
```

### 3ë‹¨ê³„: ëª¨ë¸ ì¤€ë¹„

GGUF í˜•ì‹ì˜ Vision ëª¨ë¸ì„ `~/receipt-ledger/models/` ì— ë°°ì¹˜:
```bash
mkdir -p ~/receipt-ledger/models
# ëª¨ë¸ íŒŒì¼ ë³µì‚¬ ë˜ëŠ” ë‹¤ìš´ë¡œë“œ
```

### 4ë‹¨ê³„: ì„œë²„ ì‹œìž‘

```bash
cd ~/receipt-ledger/llama.cpp/build/bin
./llama-server -m ~/receipt-ledger/models/YOUR_MODEL.gguf --host 0.0.0.0 --port 408
```

---

## âœ… ì„¤ì¹˜ ì™„ë£Œ í›„

### ì„œë²„ êµ¬ì„±

| ì„œë¹„ìŠ¤ | í¬íŠ¸ | ì„¤ëª… |
|--------|------|------|
| `llama-server` | 408 | llama.cpp Vision LLM ì„œë²„ |
| `receipt-ocr` | 9999 | OCR API ì„œë²„ |

### ì—°ê²° í…ŒìŠ¤íŠ¸
```bash
# llama.cpp ì„œë²„
curl http://localhost:408/health

# OCR API ì„œë²„
curl http://localhost:9999/health
```

---

## ðŸ”§ Systemd ì„œë¹„ìŠ¤ ì„¤ì • (ì„ íƒ)

### llama-server ì„œë¹„ìŠ¤
```bash
sudo tee /etc/systemd/system/llama-server.service > /dev/null <<EOF
[Unit]
Description=llama.cpp Vision LLM Server
After=network.target

[Service]
Type=simple
User=$USER
WorkingDirectory=$HOME/receipt-ledger/llama.cpp/build/bin
ExecStart=$HOME/receipt-ledger/llama.cpp/build/bin/llama-server -m $HOME/receipt-ledger/models/YOUR_MODEL.gguf --host 0.0.0.0 --port 408
Restart=always
RestartSec=30

[Install]
WantedBy=multi-user.target
EOF

sudo systemctl daemon-reload
sudo systemctl enable llama-server
sudo systemctl start llama-server
```

---

## ðŸ”Œ í¬íŠ¸í¬ì›Œë”© ì„¤ì •

ê³µìœ ê¸° ê´€ë¦¬ íŽ˜ì´ì§€ì—ì„œ:

1. **í¬íŠ¸ 408** â†’ ë¼ì¦ˆë² ë¦¬íŒŒì´ IP (llama.cpp ì„œë²„)
2. **í¬íŠ¸ 9999** â†’ ë¼ì¦ˆë² ë¦¬íŒŒì´ IP (OCR API)

---

## ðŸ“± ì•± ì„¤ì •

ì•±ì€ ìžë™ìœ¼ë¡œ `183.96.3.137:9999`ë¡œ OCR ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.
OCR ì„œë²„ê°€ llama.cpp ì„œë²„(`183.96.3.137:408`)ì— ì—°ê²°í•©ë‹ˆë‹¤.

---

## ðŸ’¡ ì„±ëŠ¥ íŒ

1. **ì²« ì‹¤í–‰**: ëª¨ë¸ ë¡œë”©ì— ì‹œê°„ ì†Œìš”. ì„œë¹„ìŠ¤ ì‹œìž‘ í›„ ìž ì‹œ ëŒ€ê¸° í•„ìš”
2. **ë©”ëª¨ë¦¬**: 8GB RAMì—ì„œ ë™ìž‘. ëª¨ë¸ í¬ê¸°ì— ë”°ë¼ ì„±ëŠ¥ ì°¨ì´
3. **ì–‘ìží™”**: Q4_K_M ë˜ëŠ” Q5_K_M ì–‘ìží™” ëª¨ë¸ ê¶Œìž¥
